# CNN-Heatmap
Coloring activations of a CNN to see how are the different parts of the image are being mapped. I train 2 classification model, one with good results and one with bad results. I then generate the heatmap of both models and visualize the way the good model focuses on different things, presumably the more important parts of the image and therefor gets better results.
It maybe seem like not a big difference in human sight, but behind the scences, it actually makes all the difference.

Good model:
![](images/Good%20model.png)

Bad model:
![](images/Bad%20model.png)
